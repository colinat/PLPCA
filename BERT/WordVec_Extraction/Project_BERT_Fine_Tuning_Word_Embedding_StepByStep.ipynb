{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Project_BERT_Fine_Tuning_Word_Embedding_StepByStep.ipynb","provenance":[{"file_id":"12UxbApy6YCF_5JQhy_MDP106a3d-vem5","timestamp":1583731736360},{"file_id":"1SWw0z1WIQn9xHz5UJyIdmSJyOwAL0eA-","timestamp":1583642954077},{"file_id":"1z-4hhVuEL1Zj6zbog4qTqVyPeV7k4UCA","timestamp":1583590613758}],"collapsed_sections":["G740cVdMj4vQ","AvJPErdT6x_6"],"mount_file_id":"1sIEFOqFRKVPugGHHPQQi1OmLmfoi_ZQB","authorship_tag":"ABX9TyNET2FXxYv4M0satvJPu+vD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"I9684j8bp2FD","colab_type":"text"},"source":["Reference:  \n"," https://github.com/ethanjperez/pytorch-pretrained-BERT/tree/master/examples/lm_finetuning  \n"," https://github.com/ethanjperez/pytorch-pretrained-BERT/blob/master/examples/extract_features.py\n"]},{"cell_type":"code","metadata":{"id":"eot6_cHkIxHu","colab_type":"code","outputId":"68d8bd08-771c-40be-c827-1eb955fedcdc","executionInfo":{"status":"ok","timestamp":1583888284595,"user_tz":-480,"elapsed":15898,"user":{"displayName":"Brian Sum","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOvhOiSz4aqmyleNPLH8Uei1dfjQlbNu7-t47v-w=s64","userId":"09953645826188319016"}},"colab":{"base_uri":"https://localhost:8080/","height":119}},"source":["!rm -rf NLP_Colab\n","!git clone https://github.com/sumkh/NLP_Colab.git"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Cloning into 'NLP_Colab'...\n","remote: Enumerating objects: 54, done.\u001b[K\n","remote: Counting objects:   1% (1/54)\u001b[K\rremote: Counting objects:   3% (2/54)\u001b[K\rremote: Counting objects:   5% (3/54)\u001b[K\rremote: Counting objects:   7% (4/54)\u001b[K\rremote: Counting objects:   9% (5/54)\u001b[K\rremote: Counting objects:  11% (6/54)\u001b[K\rremote: Counting objects:  12% (7/54)\u001b[K\rremote: Counting objects:  14% (8/54)\u001b[K\rremote: Counting objects:  16% (9/54)\u001b[K\rremote: Counting objects:  18% (10/54)\u001b[K\rremote: Counting objects:  20% (11/54)\u001b[K\rremote: Counting objects:  22% (12/54)\u001b[K\rremote: Counting objects:  24% (13/54)\u001b[K\rremote: Counting objects:  25% (14/54)\u001b[K\rremote: Counting objects:  27% (15/54)\u001b[K\rremote: Counting objects:  29% (16/54)\u001b[K\rremote: Counting objects:  31% (17/54)\u001b[K\rremote: Counting objects:  33% (18/54)\u001b[K\rremote: Counting objects:  35% (19/54)\u001b[K\rremote: Counting objects:  37% (20/54)\u001b[K\rremote: Counting objects:  38% (21/54)\u001b[K\rremote: Counting objects:  40% (22/54)\u001b[K\rremote: Counting objects:  42% (23/54)\u001b[K\rremote: Counting objects:  44% (24/54)\u001b[K\rremote: Counting objects:  46% (25/54)\u001b[K\rremote: Counting objects:  48% (26/54)\u001b[K\rremote: Counting objects:  50% (27/54)\u001b[K\rremote: Counting objects:  51% (28/54)\u001b[K\rremote: Counting objects:  53% (29/54)\u001b[K\rremote: Counting objects:  55% (30/54)\u001b[K\rremote: Counting objects:  57% (31/54)\u001b[K\rremote: Counting objects:  59% (32/54)\u001b[K\rremote: Counting objects:  61% (33/54)\u001b[K\rremote: Counting objects:  62% (34/54)\u001b[K\rremote: Counting objects:  64% (35/54)\u001b[K\rremote: Counting objects:  66% (36/54)\u001b[K\rremote: Counting objects:  68% (37/54)\u001b[K\rremote: Counting objects:  70% (38/54)\u001b[K\rremote: Counting objects:  72% (39/54)\u001b[K\rremote: Counting objects:  74% (40/54)\u001b[K\rremote: Counting objects:  75% (41/54)\u001b[K\rremote: Counting objects:  77% (42/54)\u001b[K\rremote: Counting objects:  79% (43/54)\u001b[K\rremote: Counting objects:  81% (44/54)\u001b[K\rremote: Counting objects:  83% (45/54)\u001b[K\rremote: Counting objects:  85% (46/54)\u001b[K\rremote: Counting objects:  87% (47/54)\u001b[K\rremote: Counting objects:  88% (48/54)\u001b[K\rremote: Counting objects:  90% (49/54)\u001b[K\rremote: Counting objects:  92% (50/54)\u001b[K\rremote: Counting objects:  94% (51/54)\u001b[K\rremote: Counting objects:  96% (52/54)\u001b[K\rremote: Counting objects:  98% (53/54)\u001b[K\rremote: Counting objects: 100% (54/54)\u001b[K\rremote: Counting objects: 100% (54/54), done.\u001b[K\n","remote: Compressing objects: 100% (47/47), done.\u001b[K\n","remote: Total 54 (delta 26), reused 15 (delta 5), pack-reused 0\u001b[K\n","Unpacking objects: 100% (54/54), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DEfSbAA4QHas","colab_type":"code","outputId":"6a7f4180-d20f-40d2-9eff-fa8d94f32d4a","executionInfo":{"status":"ok","timestamp":1583888287315,"user_tz":-480,"elapsed":18545,"user":{"displayName":"Brian Sum","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOvhOiSz4aqmyleNPLH8Uei1dfjQlbNu7-t47v-w=s64","userId":"09953645826188319016"}},"colab":{"base_uri":"https://localhost:8080/","height":97}},"source":["import tensorflow as tf\n","\n","device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","  raise SystemError('GPU device not found')\n","print('Found GPU at: {}'.format(device_name))"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Found GPU at: /device:GPU:0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"itbbpNYksjzH","colab_type":"code","outputId":"bc5df2cb-14ec-4aa5-a52d-5f8cb2a5432f","executionInfo":{"status":"ok","timestamp":1583888295460,"user_tz":-480,"elapsed":26596,"user":{"displayName":"Brian Sum","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOvhOiSz4aqmyleNPLH8Uei1dfjQlbNu7-t47v-w=s64","userId":"09953645826188319016"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["!pip install pytorch-pretrained-bert pytorch-nlp -q"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\u001b[?25l\r\u001b[K     |██▋                             | 10kB 26.5MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 20kB 33.4MB/s eta 0:00:01\r\u001b[K     |████████                        | 30kB 16.3MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 40kB 13.4MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 51kB 12.7MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 61kB 12.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 71kB 11.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 81kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 92kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 102kB 13.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 112kB 13.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 122kB 13.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 13.3MB/s \n","\u001b[?25h\u001b[?25l\r\u001b[K     |███▋                            | 10kB 30.2MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 20kB 20.6MB/s eta 0:00:01\r\u001b[K     |███████████                     | 30kB 14.2MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 40kB 11.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 51kB 12.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 61kB 11.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 71kB 11.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 81kB 11.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 92kB 7.3MB/s \n","\u001b[?25h"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ok002ceNB8E7","colab_type":"code","outputId":"dcedd216-fc07-478d-9504-0ab822a472ae","executionInfo":{"status":"ok","timestamp":1583888298024,"user_tz":-480,"elapsed":23490,"user":{"displayName":"Brian Sum","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOvhOiSz4aqmyleNPLH8Uei1dfjQlbNu7-t47v-w=s64","userId":"09953645826188319016"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["\n","import torch\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","from keras.preprocessing.sequence import pad_sequences\n","from sklearn.model_selection import train_test_split\n","from pytorch_pretrained_bert import BertTokenizer, BertConfig, BertModel, BertAdam\n","from pytorch_pretrained_bert import modeling, tokenization\n","from tqdm import tqdm, trange\n","import pandas as pd\n","import io\n","import numpy as np\n","import matplotlib.pyplot as plt\n","% matplotlib inline"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"oYsV4H8fCpZ-","colab_type":"code","outputId":"5541c894-b4cb-49a0-a51a-b252f1a1b238","executionInfo":{"status":"ok","timestamp":1583888302130,"user_tz":-480,"elapsed":1886,"user":{"displayName":"Brian Sum","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOvhOiSz4aqmyleNPLH8Uei1dfjQlbNu7-t47v-w=s64","userId":"09953645826188319016"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","n_gpu = torch.cuda.device_count()\n","torch.cuda.get_device_name(0)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Tesla P4'"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"G740cVdMj4vQ","colab_type":"text"},"source":["## Finetuning Bert Model\n","\n","The LM finetuning code is an adaption to a script from the huggingface/pytorch-transformers repository:\n","* https://github.com/huggingface/pytorch-transformers/blob/v1.0.0/examples/lm_finetuning/finetune_on_pregenerated.py\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"XL2AaqxN7vk8","colab_type":"text"},"source":["Prepare the finetuning corpus, here shown for a test corpus \"dev_corpus.txt\":\n","\n","    python pregenerate_training_data.py \\\n","    --train_corpus **name_of_copus.txt** \\\n","    --bert_model bert-base-uncased --do_lower_case \\\n","    --output_dir dev_corpus_prepared/ \\\n","    --epochs_to_generate 2 --max_seq_len 256"]},{"cell_type":"markdown","metadata":{"id":"mGLW36bk7qnK","colab_type":"text"},"source":["Run actual finetuning with:\n","\n","    python finetune_on_pregenerated.py \\\n","    --pregenerated_data dev_corpus_prepared/ \\\n","    --bert_model bert-base-uncased --do_lower_case \\\n","    --output_dir dev_corpus_finetuned/ \\\n","    --epochs 2 --train_batch_size 16"]},{"cell_type":"code","metadata":{"id":"rnN1ITCeQBKc","colab_type":"code","outputId":"4406c2c2-4ae0-4760-e867-b80cf3be8739","executionInfo":{"status":"ok","timestamp":1583670252004,"user_tz":-480,"elapsed":31790,"user":{"displayName":"Brian Sum","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOvhOiSz4aqmyleNPLH8Uei1dfjQlbNu7-t47v-w=s64","userId":"09953645826188319016"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!python NLP_Colab/pregenerate_training_data.py \\\n","    --train_corpus NLP_Colab/transcript_corpus.txt \\\n","    --bert_model bert-base-uncased --do_lower_case \\\n","    --output_dir dev_corpus_prepared/ \\\n","    --epochs_to_generate 2 --max_seq_len 256"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Loading Dataset: 115146 lines [00:16, 7085.65 lines/s]\n","Epoch:   0% 0/2 [00:00<?, ?it/s]\n","Document:   0% 0/56244 [00:00<?, ?it/s]\u001b[A\n","Document:   2% 997/56244 [00:00<00:05, 9968.61it/s]\u001b[A\n","Document:   4% 2036/56244 [00:00<00:05, 10090.69it/s]\u001b[A\n","Document:   6% 3167/56244 [00:00<00:05, 10427.14it/s]\u001b[A\n","Document:   8% 4230/56244 [00:00<00:04, 10486.85it/s]\u001b[A\n","Document:  10% 5347/56244 [00:00<00:04, 10681.51it/s]\u001b[A\n","Document:  11% 6461/56244 [00:00<00:04, 10813.66it/s]\u001b[A\n","Document:  13% 7578/56244 [00:00<00:04, 10915.90it/s]\u001b[A\n","Document:  15% 8684/56244 [00:00<00:04, 10957.87it/s]\u001b[A\n","Document:  17% 9814/56244 [00:00<00:04, 11057.48it/s]\u001b[A\n","Document:  19% 10881/56244 [00:01<00:04, 10884.66it/s]\u001b[A\n","Document:  21% 11944/56244 [00:01<00:04, 10805.54it/s]\u001b[A\n","Document:  23% 13028/56244 [00:01<00:03, 10815.50it/s]\u001b[A\n","Document:  25% 14097/56244 [00:01<00:03, 10622.89it/s]\u001b[A\n","Document:  27% 15210/56244 [00:01<00:03, 10768.84it/s]\u001b[A\n","Document:  29% 16328/56244 [00:01<00:03, 10887.16it/s]\u001b[A\n","Document:  31% 17438/56244 [00:01<00:03, 10947.83it/s]\u001b[A\n","Document:  33% 18567/56244 [00:01<00:03, 11048.14it/s]\u001b[A\n","Document:  35% 19671/56244 [00:01<00:03, 11011.94it/s]\u001b[A\n","Document:  37% 20772/56244 [00:01<00:03, 10798.49it/s]\u001b[A\n","Document:  39% 21946/56244 [00:02<00:03, 11063.69it/s]\u001b[A\n","Document:  41% 23055/56244 [00:02<00:03, 10705.93it/s]\u001b[A\n","Document:  43% 24141/56244 [00:02<00:02, 10750.34it/s]\u001b[A\n","Document:  45% 25243/56244 [00:02<00:02, 10828.94it/s]\u001b[A\n","Document:  47% 26328/56244 [00:02<00:02, 10824.30it/s]\u001b[A\n","Document:  49% 27412/56244 [00:02<00:02, 10792.77it/s]\u001b[A\n","Document:  51% 28503/56244 [00:02<00:02, 10823.50it/s]\u001b[A\n","Document:  53% 29587/56244 [00:02<00:02, 10808.11it/s]\u001b[A\n","Document:  55% 30669/56244 [00:02<00:02, 10798.44it/s]\u001b[A\n","Document:  56% 31753/56244 [00:02<00:02, 10809.32it/s]\u001b[A\n","Document:  58% 32867/56244 [00:03<00:02, 10905.74it/s]\u001b[A\n","Document:  60% 33958/56244 [00:03<00:02, 10896.54it/s]\u001b[A\n","Document:  62% 35048/56244 [00:03<00:01, 10739.65it/s]\u001b[A\n","Document:  64% 36123/56244 [00:03<00:01, 10569.17it/s]\u001b[A\n","Document:  66% 37230/56244 [00:03<00:01, 10711.01it/s]\u001b[A\n","Document:  68% 38350/56244 [00:03<00:01, 10851.95it/s]\u001b[A\n","Document:  70% 39437/56244 [00:03<00:01, 10852.84it/s]\u001b[A\n","Document:  72% 40531/56244 [00:03<00:01, 10877.31it/s]\u001b[A\n","Document:  74% 41642/56244 [00:03<00:01, 10945.53it/s]\u001b[A\n","Document:  76% 42738/56244 [00:03<00:01, 10745.10it/s]\u001b[A\n","Document:  78% 43814/56244 [00:04<00:01, 10496.30it/s]\u001b[A\n","Document:  80% 44890/56244 [00:04<00:01, 10572.75it/s]\u001b[A\n","Document:  82% 45949/56244 [00:04<00:01, 10137.72it/s]\u001b[A\n","Document:  84% 47037/56244 [00:04<00:00, 10344.73it/s]\u001b[A\n","Document:  86% 48124/56244 [00:04<00:00, 10496.85it/s]\u001b[A\n","Document:  87% 49178/56244 [00:04<00:00, 10460.03it/s]\u001b[A\n","Document:  89% 50227/56244 [00:04<00:00, 10280.07it/s]\u001b[A\n","Document:  91% 51308/56244 [00:04<00:00, 10432.64it/s]\u001b[A\n","Document:  93% 52436/56244 [00:04<00:00, 10672.02it/s]\u001b[A\n","Document:  95% 53520/56244 [00:04<00:00, 10721.30it/s]\u001b[A\n","Document:  97% 54595/56244 [00:05<00:00, 10541.19it/s]\u001b[A\n","Document:  99% 55652/56244 [00:05<00:00, 10243.47it/s]\u001b[A\n","Epoch:  50% 1/2 [00:05<00:05,  5.25s/it]\n","Document:   0% 0/56244 [00:00<?, ?it/s]\u001b[A\n","Document:   2% 1061/56244 [00:00<00:05, 10604.07it/s]\u001b[A\n","Document:   4% 2094/56244 [00:00<00:05, 10519.29it/s]\u001b[A\n","Document:   6% 3117/56244 [00:00<00:05, 10429.61it/s]\u001b[A\n","Document:   7% 4209/56244 [00:00<00:04, 10571.06it/s]\u001b[A\n","Document:   9% 5298/56244 [00:00<00:04, 10663.12it/s]\u001b[A\n","Document:  11% 6368/56244 [00:00<00:04, 10672.42it/s]\u001b[A\n","Document:  13% 7442/56244 [00:00<00:04, 10692.43it/s]\u001b[A\n","Document:  15% 8567/56244 [00:00<00:04, 10852.35it/s]\u001b[A\n","Document:  17% 9651/56244 [00:00<00:04, 10845.68it/s]\u001b[A\n","Document:  19% 10694/56244 [00:01<00:04, 10417.05it/s]\u001b[A\n","Document:  21% 11796/56244 [00:01<00:04, 10590.36it/s]\u001b[A\n","Document:  23% 12853/56244 [00:01<00:04, 10582.84it/s]\u001b[A\n","Document:  25% 13900/56244 [00:01<00:04, 10546.68it/s]\u001b[A\n","Document:  27% 15016/56244 [00:01<00:03, 10722.05it/s]\u001b[A\n","Document:  29% 16084/56244 [00:01<00:03, 10708.67it/s]\u001b[A\n","Document:  31% 17212/56244 [00:01<00:03, 10871.37it/s]\u001b[A\n","Document:  33% 18377/56244 [00:01<00:03, 11091.62it/s]\u001b[A\n","Document:  35% 19486/56244 [00:01<00:03, 11043.97it/s]\u001b[A\n","Document:  37% 20596/56244 [00:01<00:03, 11060.60it/s]\u001b[A\n","Document:  39% 21702/56244 [00:02<00:03, 10949.74it/s]\u001b[A\n","Document:  41% 22798/56244 [00:02<00:03, 10672.36it/s]\u001b[A\n","Document:  42% 23867/56244 [00:02<00:03, 10633.15it/s]\u001b[A\n","Document:  44% 24982/56244 [00:02<00:02, 10780.81it/s]\u001b[A\n","Document:  46% 26062/56244 [00:02<00:02, 10596.10it/s]\u001b[A\n","Document:  48% 27170/56244 [00:02<00:02, 10734.49it/s]\u001b[A\n","Document:  50% 28247/56244 [00:02<00:02, 10744.27it/s]\u001b[A\n","Document:  52% 29344/56244 [00:02<00:02, 10809.02it/s]\u001b[A\n","Document:  54% 30462/56244 [00:02<00:02, 10916.53it/s]\u001b[A\n","Document:  56% 31608/56244 [00:02<00:02, 11070.26it/s]\u001b[A\n","Document:  58% 32717/56244 [00:03<00:02, 10602.29it/s]\u001b[A\n","Document:  60% 33783/56244 [00:03<00:02, 10379.53it/s]\u001b[A\n","Document:  62% 34913/56244 [00:03<00:02, 10638.19it/s]\u001b[A\n","Document:  64% 35988/56244 [00:03<00:01, 10667.66it/s]\u001b[A\n","Document:  66% 37085/56244 [00:03<00:01, 10753.09it/s]\u001b[A\n","Document:  68% 38163/56244 [00:03<00:01, 10736.11it/s]\u001b[A\n","Document:  70% 39267/56244 [00:03<00:01, 10825.02it/s]\u001b[A\n","Document:  72% 40401/56244 [00:03<00:01, 10973.25it/s]\u001b[A\n","Document:  74% 41527/56244 [00:03<00:01, 11056.40it/s]\u001b[A\n","Document:  76% 42634/56244 [00:03<00:01, 10832.17it/s]\u001b[A\n","Document:  78% 43720/56244 [00:04<00:01, 10736.21it/s]\u001b[A\n","Document:  80% 44821/56244 [00:04<00:01, 10815.00it/s]\u001b[A\n","Document:  82% 45904/56244 [00:04<00:00, 10688.40it/s]\u001b[A\n","Document:  84% 46974/56244 [00:04<00:00, 10622.51it/s]\u001b[A\n","Document:  85% 48063/56244 [00:04<00:00, 10700.00it/s]\u001b[A\n","Document:  87% 49134/56244 [00:04<00:00, 10560.74it/s]\u001b[A\n","Document:  89% 50248/56244 [00:04<00:00, 10727.68it/s]\u001b[A\n","Document:  91% 51334/56244 [00:04<00:00, 10766.99it/s]\u001b[A\n","Document:  93% 52416/56244 [00:04<00:00, 10779.41it/s]\u001b[A\n","Document:  95% 53514/56244 [00:04<00:00, 10838.09it/s]\u001b[A\n","Document:  97% 54599/56244 [00:05<00:00, 10573.79it/s]\u001b[A\n","Document:  99% 55709/56244 [00:05<00:00, 10725.48it/s]\u001b[A\n","Epoch: 100% 2/2 [00:10<00:00,  5.25s/it]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YnQlBdB3TUTY","colab_type":"code","outputId":"99955eb0-4ca2-4f96-b0a2-a5e42e5cf481","executionInfo":{"status":"ok","timestamp":1583670503722,"user_tz":-480,"elapsed":8621,"user":{"displayName":"Brian Sum","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOvhOiSz4aqmyleNPLH8Uei1dfjQlbNu7-t47v-w=s64","userId":"09953645826188319016"}},"colab":{"base_uri":"https://localhost:8080/","height":102}},"source":["# Copy the files to a directory in your Google Drive.\n","!cp -r ./dev_corpus_prepared/ \"./drive/My Drive/EBAC_G/NLP_Project/Embeddings/\"\n","\n","# Zip up the folder and copy zip file to Google Drive\n","!zip -r /content/dev_corpus_prepared.zip /content/dev_corpus_prepared\n","!cp -r /content/dev_corpus_prepared.zip \"./drive/My Drive/EBAC_G/NLP_Project/Embeddings/\"\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["  adding: content/dev_corpus_prepared/ (stored 0%)\n","  adding: content/dev_corpus_prepared/epoch_1.json (deflated 81%)\n","  adding: content/dev_corpus_prepared/epoch_0.json (deflated 81%)\n","  adding: content/dev_corpus_prepared/epoch_0_metrics.json (stored 0%)\n","  adding: content/dev_corpus_prepared/epoch_1_metrics.json (stored 0%)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"simxDe63YjgY","colab_type":"code","outputId":"24698f04-c741-41ba-cca0-61d24b60805f","executionInfo":{"status":"ok","timestamp":1583674755839,"user_tz":-480,"elapsed":4233797,"user":{"displayName":"Brian Sum","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOvhOiSz4aqmyleNPLH8Uei1dfjQlbNu7-t47v-w=s64","userId":"09953645826188319016"}},"colab":{"base_uri":"https://localhost:8080/","height":581}},"source":["!python NLP_Colab/finetune_on_pregenerated.py \\\n","    --pregenerated_data dev_corpus_prepared/ \\\n","    --bert_model bert-base-uncased --do_lower_case \\\n","    --output_dir dev_corpus_finetuned/ \\\n","    --epochs 2 --train_batch_size 16"],"execution_count":0,"outputs":[{"output_type":"stream","text":["2020-03-08 12:28:44,030: device: cuda n_gpu: 1, distributed training: False, 16-bits training: False\n","2020-03-08 12:28:44,309: loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","2020-03-08 12:28:44,749: loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n","2020-03-08 12:28:44,750: extracting archive file /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmp9duwzvvv\n","2020-03-08 12:28:48,406: Model config {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"max_position_embeddings\": 512,\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","2020-03-08 12:28:54,070: ***** Running training *****\n","2020-03-08 12:28:54,070:   Num examples = 114952\n","2020-03-08 12:28:54,070:   Batch size = 16\n","2020-03-08 12:28:54,070:   Num steps = 7184\n","2020-03-08 12:28:54,100: Loading training examples for epoch 0\n","Training examples: 100% 57490/57490 [00:02<00:00, 21160.71it/s]\n","2020-03-08 12:28:56,817: Loading complete!\n","Epoch 0: 100% 3594/3594 [35:07<00:00,  2.20it/s, Loss: 2.27406]\n","2020-03-08 13:04:04,418: Loading training examples for epoch 1\n","Training examples: 100% 57462/57462 [00:02<00:00, 21210.84it/s]\n","2020-03-08 13:04:07,128: Loading complete!\n","Epoch 1: 100% 3592/3592 [35:06<00:00,  2.04it/s, Loss: 1.93704]2020-03-08 13:39:13,727: Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n","\n","2020-03-08 13:39:13,784: ** ** * Saving fine-tuned model ** ** * \n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"6SSW4qr0GwAN","colab_type":"text"},"source":["#### Download Fine-Tuned BERT Model"]},{"cell_type":"code","metadata":{"id":"CmQt0ZBAYtSp","colab_type":"code","outputId":"38772dcb-493a-4aef-d3d0-51a13d86392d","executionInfo":{"status":"ok","timestamp":1583674959944,"user_tz":-480,"elapsed":2982,"user":{"displayName":"Brian Sum","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOvhOiSz4aqmyleNPLH8Uei1dfjQlbNu7-t47v-w=s64","userId":"09953645826188319016"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["!ls -l --block-size=K ./dev_corpus_finetuned/"],"execution_count":0,"outputs":[{"output_type":"stream","text":["total 430388K\n","-rw-r--r-- 1 root root      1K Mar  8 13:39 config.json\n","-rw-r--r-- 1 root root 430152K Mar  8 13:39 pytorch_model.bin\n","-rw-r--r-- 1 root root    227K Mar  8 13:39 vocab.txt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aSoROn3fY_CK","colab_type":"code","outputId":"76e9fb85-e1f6-4f1a-b0b9-0e3be6eb4f3f","executionInfo":{"status":"ok","timestamp":1583675018658,"user_tz":-480,"elapsed":29900,"user":{"displayName":"Brian Sum","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOvhOiSz4aqmyleNPLH8Uei1dfjQlbNu7-t47v-w=s64","userId":"09953645826188319016"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["# Copy the model files to a directory in your Google Drive.\n","!cp -r ./dev_corpus_finetuned/ \"./drive/My Drive/EBAC_G/NLP_Project/Embeddings/\"\n","\n","# Zip up the folder and copy zip file to Google Drive\n","!zip -r /content/dev_corpus_finetuned.zip /content/dev_corpus_finetuned\n","!cp -r /content/dev_corpus_finetuned.zip \"./drive/My Drive/EBAC_G/NLP_Project/Embeddings/\"\n","\n","#If want to download from google.colab import files (slower) \n","#files.download(\"/content/dev_corpus_finetuned.zip\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["  adding: content/dev_corpus_finetuned/ (stored 0%)\n","  adding: content/dev_corpus_finetuned/pytorch_model.bin (deflated 7%)\n","  adding: content/dev_corpus_finetuned/vocab.txt (deflated 53%)\n","  adding: content/dev_corpus_finetuned/config.json (deflated 47%)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"AvJPErdT6x_6","colab_type":"text"},"source":["## Extract Words Embeddings with Bert-Base-Uncased (Examples)"]},{"cell_type":"markdown","metadata":{"id":"Kt47SLl_Jo-U","colab_type":"text"},"source":["As an example, we include the script extract_features.py which can be used like this:  \n","https://github.com/ethanjperez/pytorch-pretrained-BERT/blob/master/examples/extract_features.py  \n","\n","**Please use the one from my NLP_Colab Github respository which is an adapted version.**"]},{"cell_type":"code","metadata":{"id":"kItPvsUajDGn","colab_type":"code","outputId":"6fa969be-6411-40d0-a81a-367e1d2a2587","executionInfo":{"status":"ok","timestamp":1583792797751,"user_tz":-480,"elapsed":35206,"user":{"displayName":"Brian Sum","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOvhOiSz4aqmyleNPLH8Uei1dfjQlbNu7-t47v-w=s64","userId":"09953645826188319016"}},"colab":{"base_uri":"https://localhost:8080/","height":819}},"source":["# Sentence A and Sentence B are separated by the ||| delimiter for sentence\n","# pair tasks like question answering and entailment.\n","# For single sentence inputs, put one sentence per line and DON'T use the\n","# delimiter.\n","\n","!echo 'Who was Jim Henson ? ||| Jim Henson was a puppeteer' > input.txt\n","\n","# https://github.com/google-research/bert/blob/master/README.md\n","# Download BERT Model to your drive:\n","# https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip\n","\n","#input_file=\"./input.txt\"\n","input_file=\"NLP_Colab/transcript_corpus_healthcare.txt\"\n","output_file=\"./bert_base_WordVectors.json\"\n","\n","bert_master=\"./NLP_Colab\"\n","\n","!python $bert_master/extract_features.py \\\n","  --input_file=$input_file \\\n","  --output_file=$output_file \\\n","  --bert_model bert-base-uncased --do_lower_case \\\n","  --layers=-1,-2,-3,-4 \\\n","  --max_seq_length=128 \\\n","  --batch_size=8"],"execution_count":0,"outputs":[{"output_type":"stream","text":["03/09/2020 22:26:11 - INFO - __main__ -   device: cuda n_gpu: 1 distributed training: False\n","03/09/2020 22:26:11 - INFO - pytorch_pretrained_bert.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache, downloading to /tmp/tmp3iq_chfm\n","\r  0% 0/231508 [00:00<?, ?B/s]\r 23% 52224/231508 [00:00<00:00, 399046.36B/s]\r100% 231508/231508 [00:00<00:00, 1161337.19B/s]\n","03/09/2020 22:26:12 - INFO - pytorch_pretrained_bert.file_utils -   copying /tmp/tmp3iq_chfm to cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","03/09/2020 22:26:12 - INFO - pytorch_pretrained_bert.file_utils -   creating metadata file for /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","03/09/2020 22:26:12 - INFO - pytorch_pretrained_bert.file_utils -   removing temp file /tmp/tmp3iq_chfm\n","03/09/2020 22:26:12 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n","03/09/2020 22:26:12 - INFO - __main__ -   *** Example ***\n","03/09/2020 22:26:12 - INFO - __main__ -   unique_id: 0\n","03/09/2020 22:26:12 - INFO - __main__ -   tokens: [CLS] today i ' ll highlight recent pipeline updates and discuss some of the key milestone ##s we anti ##ci ##pate for the remainder of 2017 . [SEP] i ' ll start with our hem - on ##c programs , where we continue to make significant progress with both im ##br ##u ##vic ##a and ve ##nc ##le ##xt ##a [SEP]\n","03/09/2020 22:26:12 - INFO - __main__ -   input_ids: 101 2651 1045 1005 2222 12944 3522 13117 14409 1998 6848 2070 1997 1996 3145 19199 2015 2057 3424 6895 17585 2005 1996 6893 1997 2418 1012 102 1045 1005 2222 2707 2007 2256 19610 1011 2006 2278 3454 1010 2073 2057 3613 2000 2191 3278 5082 2007 2119 10047 19892 2226 7903 2050 1998 2310 12273 2571 18413 2050 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/09/2020 22:26:12 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/09/2020 22:26:12 - INFO - __main__ -   input_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/09/2020 22:26:12 - INFO - __main__ -   *** Example ***\n","03/09/2020 22:26:12 - INFO - __main__ -   unique_id: 1\n","03/09/2020 22:26:12 - INFO - __main__ -   tokens: [CLS] starting with im ##br ##u ##vic ##a , as we ' ve outlined , expanding into new indications is an important driver of future growth [SEP] earlier this year we added re ##la ##pse ##d / ref ##rac ##tory marginal zone l ##ym ##ph ##oma to our growing list of approved uses , and we continue to make progress with other indications as well [SEP]\n","03/09/2020 22:26:12 - INFO - __main__ -   input_ids: 101 3225 2007 10047 19892 2226 7903 2050 1010 2004 2057 1005 2310 14801 1010 9186 2046 2047 24936 2003 2019 2590 4062 1997 2925 3930 102 3041 2023 2095 2057 2794 2128 2721 29251 2094 1013 25416 22648 7062 14785 4224 1048 24335 8458 9626 2000 2256 3652 2862 1997 4844 3594 1010 1998 2057 3613 2000 2191 5082 2007 2060 24936 2004 2092 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/09/2020 22:26:12 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/09/2020 22:26:12 - INFO - __main__ -   input_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/09/2020 22:26:12 - INFO - __main__ -   *** Example ***\n","03/09/2020 22:26:12 - INFO - __main__ -   unique_id: 2\n","03/09/2020 22:26:12 - INFO - __main__ -   tokens: [CLS] during the quarter , we submitted a supplemental new drug application for the use of im ##br ##u ##vic ##a in patients with chronic graf ##t - versus - host - disease who failed prior systemic therapy [SEP]\n","03/09/2020 22:26:12 - INFO - __main__ -   input_ids: 101 2076 1996 4284 1010 2057 7864 1037 27024 2047 4319 4646 2005 1996 2224 1997 10047 19892 2226 7903 2050 1999 5022 2007 11888 22160 2102 1011 6431 1011 3677 1011 4295 2040 3478 3188 22575 7242 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/09/2020 22:26:12 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/09/2020 22:26:12 - INFO - __main__ -   input_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/09/2020 22:26:12 - INFO - pytorch_pretrained_bert.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz not found in cache, downloading to /tmp/tmp3m0wt_5o\n","100% 407873900/407873900 [00:11<00:00, 36918112.66B/s]\n","03/09/2020 22:26:23 - INFO - pytorch_pretrained_bert.file_utils -   copying /tmp/tmp3m0wt_5o to cache at /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n","03/09/2020 22:26:24 - INFO - pytorch_pretrained_bert.file_utils -   creating metadata file for /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n","03/09/2020 22:26:24 - INFO - pytorch_pretrained_bert.file_utils -   removing temp file /tmp/tmp3m0wt_5o\n","03/09/2020 22:26:24 - INFO - pytorch_pretrained_bert.modeling -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n","03/09/2020 22:26:24 - INFO - pytorch_pretrained_bert.modeling -   extracting archive file /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpuc6hnkzh\n","03/09/2020 22:26:29 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"max_position_embeddings\": 512,\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9dJTMCE9GI2W","colab_type":"code","outputId":"972c69c7-e6c9-4cc3-90b4-881e23a53170","executionInfo":{"status":"ok","timestamp":1583792895656,"user_tz":-480,"elapsed":4594,"user":{"displayName":"Brian Sum","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOvhOiSz4aqmyleNPLH8Uei1dfjQlbNu7-t47v-w=s64","userId":"09953645826188319016"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Zip up the folder and copy zip file to Google Drive\n","!zip -r /content/bert_base_WordVectors.zip /content/bert_base_WordVectors.json\n","!cp -r /content/bert_base_WordVectors.zip \"./drive/My Drive/Downloads\""],"execution_count":0,"outputs":[{"output_type":"stream","text":["  adding: content/bert_base_WordVectors.json (deflated 62%)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"dXdwVGDfcSjG","colab_type":"text"},"source":["# Using Fine-Tune Model"]},{"cell_type":"code","metadata":{"id":"NxKcgZDWToZS","colab_type":"code","outputId":"afaca20b-3b78-46c1-9375-3921dbfe4e65","executionInfo":{"status":"ok","timestamp":1583888328430,"user_tz":-480,"elapsed":22548,"user":{"displayName":"Brian Sum","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOvhOiSz4aqmyleNPLH8Uei1dfjQlbNu7-t47v-w=s64","userId":"09953645826188319016"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# Load a trained model and vocabulary that you have fine-tuned\n","#output_dir = './model_save/'\n","output_dir = './drive/My Drive/EBAC_G/NLP_Project/Embeddings/dev_corpus_finetuned/'\n","#model = model_class.from_pretrained(output_dir)\n","model = BertModel.from_pretrained(output_dir)\n","#tokenizer = tokenizer_class.from_pretrained(output_dir)\n","tokenizer = BertTokenizer.from_pretrained(output_dir)\n","\n","# Copy the model to the GPU.\n","model.to(device)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BertModel(\n","  (embeddings): BertEmbeddings(\n","    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","    (position_embeddings): Embedding(512, 768)\n","    (token_type_embeddings): Embedding(2, 768)\n","    (LayerNorm): BertLayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (encoder): BertEncoder(\n","    (layer): ModuleList(\n","      (0): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (1): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (2): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (3): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (4): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (5): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (6): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (7): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (8): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (9): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (10): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (11): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","  )\n","  (pooler): BertPooler(\n","    (dense): Linear(in_features=768, out_features=768, bias=True)\n","    (activation): Tanh()\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"M0wsn74Swo62","colab_type":"code","colab":{}},"source":["#!echo 'Who was Jim Henson ? ||| Jim Henson was a puppeteer' > input.txt\n","#input_file=\"./input.txt\"\n","input_file=\"NLP_Colab/transcript_corpus_healthcare.txt\"\n","layer_indexes = [-1,-2,-3,-4]\n","batch_size = 8 \n","local_rank = -1 #local_rank for distributed training on gpus"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a16cEJAXq-or","colab_type":"text"},"source":["#### Import Packages"]},{"cell_type":"code","metadata":{"id":"R_l0_q_PneL4","colab_type":"code","colab":{}},"source":["import argparse\n","import collections\n","import logging\n","import json\n","import re\n","\n","import torch\n","from torch.utils.data import TensorDataset, DataLoader, SequentialSampler\n","from torch.utils.data.distributed import DistributedSampler\n","\n","from pytorch_pretrained_bert.tokenization import BertTokenizer\n","from pytorch_pretrained_bert.modeling import BertModel\n","\n","logging.basicConfig(format = '%(asctime)s - %(levelname)s - %(name)s -   %(message)s', \n","                    datefmt = '%m/%d/%Y %H:%M:%S',\n","                    level = logging.INFO)\n","logger = logging.getLogger(__name__)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NRjAkrBrpiUp","colab_type":"text"},"source":["#### read_examples(input_file)\n","**Return examples**  \n","example.InputExample(unique_id=unique_id, text_a=text_a, text_b=text_b))"]},{"cell_type":"code","metadata":{"id":"pxhLs6pypujj","colab_type":"code","colab":{}},"source":["class InputExample(object):\n","\n","    def __init__(self, unique_id, text_a, text_b):\n","        self.unique_id = unique_id\n","        self.text_a = text_a\n","        self.text_b = text_b\n","\n","examples = []\n","unique_id = 0\n","with open(input_file, \"r\", encoding='utf-8') as reader:\n","    while True:\n","        line = reader.readline()\n","        if not line:\n","            break\n","        line = line.strip()\n","        text_a = None\n","        text_b = None\n","        m = re.match(r\"^(.*) \\|\\|\\| (.*)$\", line)\n","        if m is None:\n","            text_a = line\n","        else:\n","            text_a = m.group(1)\n","            text_b = m.group(2)\n","            \n","        examples.append(InputExample(unique_id=unique_id, text_a=text_a, text_b=text_b))\n","        unique_id += 1\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"b5tixY6PFEiU","colab_type":"code","outputId":"6d88a692-89c6-464e-d4f5-84958c037dd3","executionInfo":{"status":"ok","timestamp":1583888344409,"user_tz":-480,"elapsed":799,"user":{"displayName":"Brian Sum","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOvhOiSz4aqmyleNPLH8Uei1dfjQlbNu7-t47v-w=s64","userId":"09953645826188319016"}},"colab":{"base_uri":"https://localhost:8080/","height":88}},"source":["print(examples[0].unique_id)\n","print(examples[0].text_a)\n","print(examples[0].text_b)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["0\n","Today I'll highlight recent pipeline updates and discuss some of the key milestones we anticipate for the remainder of 2017.\n","I'll start with our hem-onc programs, where we continue to make significant progress with both Imbruvica and Venclexta\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"t-f4VNbSpJSl","colab_type":"text"},"source":["#### convert_examples_to_features(examples, seq_length, tokenizer)  \n","**Return features**   \n","features.InputFeatures(unique_id=example.unique_id, \n","tokens=tokens,\n","input_ids=input_ids,\n","input_mask=input_mask,\n","input_type_ids=input_type_ids))"]},{"cell_type":"code","metadata":{"id":"ZpkdSigIout5","colab_type":"code","outputId":"61c75124-7aad-4cd0-8fee-5e1da719d181","executionInfo":{"status":"ok","timestamp":1583888353462,"user_tz":-480,"elapsed":859,"user":{"displayName":"Brian Sum","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOvhOiSz4aqmyleNPLH8Uei1dfjQlbNu7-t47v-w=s64","userId":"09953645826188319016"}},"colab":{"base_uri":"https://localhost:8080/","height":343}},"source":["seq_length = 128 \n","# type=int\n","# The maximum total input sequence length after WordPiece tokenization. \n","# Sequences longer than this will be truncated, and sequences shorter than this will be padded.\n","\n","def _truncate_seq_pair(tokens_a, tokens_b, max_length):\n","    \"\"\"Truncates a sequence pair in place to the maximum length.\"\"\"\n","\n","    # This is a simple heuristic which will always truncate the longer sequence\n","    # one token at a time. This makes more sense than truncating an equal percent\n","    # of tokens from each, since if one sequence is very short then each token\n","    # that's truncated likely contains more information than a longer sequence.\n","    while True:\n","        total_length = len(tokens_a) + len(tokens_b)\n","        if total_length <= max_length:\n","            break\n","        if len(tokens_a) > len(tokens_b):\n","            tokens_a.pop()\n","        else:\n","            tokens_b.pop()\n","\n","class InputFeatures(object):\n","    \"\"\"A single set of features of data.\"\"\"\n","\n","    def __init__(self, unique_id, tokens, input_ids, input_mask, input_type_ids):\n","        self.unique_id = unique_id\n","        self.tokens = tokens\n","        self.input_ids = input_ids\n","        self.input_mask = input_mask\n","        self.input_type_ids = input_type_ids\n","\n","features = []\n","for (ex_index, example) in enumerate(examples):\n","    tokens_a = tokenizer.tokenize(example.text_a)\n","\n","    tokens_b = None\n","    if example.text_b:\n","        tokens_b = tokenizer.tokenize(example.text_b)\n","\n","    if tokens_b:\n","        # Modifies `tokens_a` and `tokens_b` in place so that the total\n","        # length is less than the specified length.\n","        # Account for [CLS], [SEP], [SEP] with \"- 3\"\n","        _truncate_seq_pair(tokens_a, tokens_b, seq_length - 3)\n","    else:\n","        # Account for [CLS] and [SEP] with \"- 2\"\n","        if len(tokens_a) > seq_length - 2:\n","            tokens_a = tokens_a[0:(seq_length - 2)]\n","\n","    tokens = []\n","    input_type_ids = []\n","    tokens.append(\"[CLS]\")\n","    input_type_ids.append(0)\n","    for token in tokens_a:\n","        tokens.append(token)\n","        input_type_ids.append(0)\n","    tokens.append(\"[SEP]\")\n","    input_type_ids.append(0)\n","\n","    if tokens_b:\n","        for token in tokens_b:\n","            tokens.append(token)\n","            input_type_ids.append(1)\n","        tokens.append(\"[SEP]\")\n","        input_type_ids.append(1)\n","\n","    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n","\n","    # The mask has 1 for real tokens and 0 for padding tokens. Only real\n","    # tokens are attended to.\n","    input_mask = [1] * len(input_ids)\n","\n","    # Zero-pad up to the sequence length.\n","    while len(input_ids) < seq_length:\n","        input_ids.append(0)\n","        input_mask.append(0)\n","        input_type_ids.append(0)\n","\n","    assert len(input_ids) == seq_length\n","    assert len(input_mask) == seq_length\n","    assert len(input_type_ids) == seq_length\n","\n","    if ex_index < 5:\n","        logger.info(\"******\")\n","        logger.info(\"unique_id: %s\" % (example.unique_id))\n","        logger.info(\"tokens: %s\" % \" \".join([str(x) for x in tokens]))\n","        logger.info(\"input_ids: %s\" % \" \".join([str(x) for x in input_ids]))\n","        logger.info(\"input_mask: %s\" % \" \".join([str(x) for x in input_mask]))\n","        logger.info(\n","            \"input_type_ids: %s\" % \" \".join([str(x) for x in input_type_ids]))\n","        \n","    features.append(InputFeatures(\n","                unique_id=example.unique_id,\n","                tokens=tokens,\n","                input_ids=input_ids,\n","                input_mask=input_mask,\n","                input_type_ids=input_type_ids))\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["03/11/2020 00:59:12 - INFO - __main__ -   ******\n","03/11/2020 00:59:12 - INFO - __main__ -   unique_id: 0\n","03/11/2020 00:59:12 - INFO - __main__ -   tokens: [CLS] today i ' ll highlight recent pipeline updates and discuss some of the key milestone ##s we anti ##ci ##pate for the remainder of 2017 . [SEP] i ' ll start with our hem - on ##c programs , where we continue to make significant progress with both im ##br ##u ##vic ##a and ve ##nc ##le ##xt ##a [SEP]\n","03/11/2020 00:59:12 - INFO - __main__ -   input_ids: 101 2651 1045 1005 2222 12944 3522 13117 14409 1998 6848 2070 1997 1996 3145 19199 2015 2057 3424 6895 17585 2005 1996 6893 1997 2418 1012 102 1045 1005 2222 2707 2007 2256 19610 1011 2006 2278 3454 1010 2073 2057 3613 2000 2191 3278 5082 2007 2119 10047 19892 2226 7903 2050 1998 2310 12273 2571 18413 2050 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/11/2020 00:59:12 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/11/2020 00:59:12 - INFO - __main__ -   input_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/11/2020 00:59:13 - INFO - __main__ -   ******\n","03/11/2020 00:59:13 - INFO - __main__ -   unique_id: 1\n","03/11/2020 00:59:13 - INFO - __main__ -   tokens: [CLS] starting with im ##br ##u ##vic ##a , as we ' ve outlined , expanding into new indications is an important driver of future growth [SEP] earlier this year we added re ##la ##pse ##d / ref ##rac ##tory marginal zone l ##ym ##ph ##oma to our growing list of approved uses , and we continue to make progress with other indications as well [SEP]\n","03/11/2020 00:59:13 - INFO - __main__ -   input_ids: 101 3225 2007 10047 19892 2226 7903 2050 1010 2004 2057 1005 2310 14801 1010 9186 2046 2047 24936 2003 2019 2590 4062 1997 2925 3930 102 3041 2023 2095 2057 2794 2128 2721 29251 2094 1013 25416 22648 7062 14785 4224 1048 24335 8458 9626 2000 2256 3652 2862 1997 4844 3594 1010 1998 2057 3613 2000 2191 5082 2007 2060 24936 2004 2092 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/11/2020 00:59:13 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/11/2020 00:59:13 - INFO - __main__ -   input_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/11/2020 00:59:13 - INFO - __main__ -   ******\n","03/11/2020 00:59:13 - INFO - __main__ -   unique_id: 2\n","03/11/2020 00:59:13 - INFO - __main__ -   tokens: [CLS] during the quarter , we submitted a supplemental new drug application for the use of im ##br ##u ##vic ##a in patients with chronic graf ##t - versus - host - disease who failed prior systemic therapy [SEP]\n","03/11/2020 00:59:13 - INFO - __main__ -   input_ids: 101 2076 1996 4284 1010 2057 7864 1037 27024 2047 4319 4646 2005 1996 2224 1997 10047 19892 2226 7903 2050 1999 5022 2007 11888 22160 2102 1011 6431 1011 3677 1011 4295 2040 3478 3188 22575 7242 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/11/2020 00:59:13 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","03/11/2020 00:59:13 - INFO - __main__ -   input_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"OhWz7BP7qITX","colab_type":"code","outputId":"83114466-5bb3-42aa-ab8e-6240c801b5ae","executionInfo":{"status":"ok","timestamp":1583888361574,"user_tz":-480,"elapsed":753,"user":{"displayName":"Brian Sum","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOvhOiSz4aqmyleNPLH8Uei1dfjQlbNu7-t47v-w=s64","userId":"09953645826188319016"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["print(features[0].unique_id)\n","print(features[0].tokens)\n","print(features[0].input_ids)\n","print(features[0].input_mask)\n","print(features[0].input_type_ids)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["0\n","['[CLS]', 'today', 'i', \"'\", 'll', 'highlight', 'recent', 'pipeline', 'updates', 'and', 'discuss', 'some', 'of', 'the', 'key', 'milestone', '##s', 'we', 'anti', '##ci', '##pate', 'for', 'the', 'remainder', 'of', '2017', '.', '[SEP]', 'i', \"'\", 'll', 'start', 'with', 'our', 'hem', '-', 'on', '##c', 'programs', ',', 'where', 'we', 'continue', 'to', 'make', 'significant', 'progress', 'with', 'both', 'im', '##br', '##u', '##vic', '##a', 'and', 've', '##nc', '##le', '##xt', '##a', '[SEP]']\n","[101, 2651, 1045, 1005, 2222, 12944, 3522, 13117, 14409, 1998, 6848, 2070, 1997, 1996, 3145, 19199, 2015, 2057, 3424, 6895, 17585, 2005, 1996, 6893, 1997, 2418, 1012, 102, 1045, 1005, 2222, 2707, 2007, 2256, 19610, 1011, 2006, 2278, 3454, 1010, 2073, 2057, 3613, 2000, 2191, 3278, 5082, 2007, 2119, 10047, 19892, 2226, 7903, 2050, 1998, 2310, 12273, 2571, 18413, 2050, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ImnmBDXnp7fL","colab_type":"text"},"source":["#### Function to Extract Words Embeddings"]},{"cell_type":"code","metadata":{"id":"dr9APuhBmKMH","colab_type":"code","colab":{}},"source":["unique_id_to_feature = {}\n","for feature in features:\n","    unique_id_to_feature[feature.unique_id] = feature\n","\n","if local_rank != -1:\n","    model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[local_rank], output_device=local_rank)\n","elif n_gpu > 1:\n","    model = torch.nn.DataParallel(model)\n","\n","all_input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long) # Token ids for every sentences in individual list\n","all_input_mask = torch.tensor([f.input_mask for f in features], dtype=torch.long)\n","all_example_index = torch.arange(all_input_ids.size(0), dtype=torch.long) # Index for each sentences in one list\n","\n","eval_data = TensorDataset(all_input_ids, all_input_mask, all_example_index)\n","if local_rank == -1:\n","    eval_sampler = SequentialSampler(eval_data)\n","else:\n","    eval_sampler = DistributedSampler(eval_data)\n","eval_dataloader = DataLoader(eval_data, sampler=eval_sampler, batch_size=batch_size)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7c4n1kSLpsuL","colab_type":"code","colab":{}},"source":["model.eval()\n","\n","for input_ids, input_mask, example_indices in eval_dataloader:\n","    input_ids = input_ids.to(device)\n","    input_mask = input_mask.to(device)\n","\n","    all_encoder_layers, _ = model(input_ids, token_type_ids=None, attention_mask=input_mask)\n","    all_encoder_layers = all_encoder_layers\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eC4eabMRu8Fa","colab_type":"code","outputId":"a89e4d9d-9571-465c-cbef-ff90802897e5","executionInfo":{"status":"ok","timestamp":1583888382057,"user_tz":-480,"elapsed":738,"user":{"displayName":"Brian Sum","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOvhOiSz4aqmyleNPLH8Uei1dfjQlbNu7-t47v-w=s64","userId":"09953645826188319016"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["# The encoder_layers are arranged in 12 layers with tensor of shape [batch,[tokens,[values]]]\n","print (\"Number of layers:\", len(all_encoder_layers))\n","###\n","layer_i = 0\n","print (\"Number of batches:\", len(all_encoder_layers[layer_i]))\n","###\n","batch_i = 0\n","print (\"Number of tokens:\", len(all_encoder_layers[layer_i][batch_i]))\n","###\n","token_i = 0\n","print (\"Number of hidden units:\", len(all_encoder_layers[layer_i][batch_i][token_i]))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Number of layers: 12\n","Number of batches: 3\n","Number of tokens: 128\n","Number of hidden units: 768\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HOgV_5j_vntD","colab_type":"code","outputId":"f2f93353-b741-46d3-a98e-9e148710ed31","executionInfo":{"status":"ok","timestamp":1583888390776,"user_tz":-480,"elapsed":735,"user":{"displayName":"Brian Sum","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOvhOiSz4aqmyleNPLH8Uei1dfjQlbNu7-t47v-w=s64","userId":"09953645826188319016"}},"colab":{"base_uri":"https://localhost:8080/","height":425}},"source":["# See the last layer #12\n","all_encoder_layers[11]"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[-0.0251, -0.0262,  0.1480,  ..., -0.0864,  0.1275,  0.0645],\n","         [-0.5629,  0.3367, -0.0777,  ..., -0.0927, -0.2534, -0.5458],\n","         [ 0.3086, -0.2407,  0.4622,  ...,  0.1691,  0.1212,  0.3951],\n","         ...,\n","         [ 0.2921, -0.1022,  0.6603,  ...,  0.2839,  0.3485, -0.2601],\n","         [-0.1776,  0.1837,  0.4692,  ..., -0.0349,  0.1239, -0.4477],\n","         [ 0.0608, -0.1094,  0.7411,  ...,  0.1748,  0.2386, -0.2449]],\n","\n","        [[-0.0486, -0.8811,  0.3280,  ...,  0.5144,  0.0869,  0.1515],\n","         [-0.7318,  0.1354, -0.0150,  ...,  0.3905,  0.1757, -0.4784],\n","         [-1.0090,  0.0145, -0.4233,  ..., -0.0203, -0.4211,  0.2620],\n","         ...,\n","         [ 0.1774,  0.1078,  0.7221,  ...,  0.1357,  0.2403, -0.0891],\n","         [-0.2437,  0.2591,  0.5148,  ..., -0.1526, -0.1959,  0.5269],\n","         [-0.0334, -0.0660,  0.5553,  ...,  0.0817,  0.1350,  0.1763]],\n","\n","        [[-0.2028, -0.9558,  0.0365,  ...,  0.4932,  0.1534,  0.3602],\n","         [-1.7544,  0.2825,  0.1185,  ..., -0.2920, -0.5925, -0.4613],\n","         [-1.2980, -0.7088, -0.5081,  ...,  0.2190,  0.5236, -0.6538],\n","         ...,\n","         [ 0.0162,  0.2106,  0.6318,  ..., -0.0172,  0.1602,  0.2092],\n","         [-0.3161,  0.0222,  0.4348,  ..., -0.1590,  0.0027,  0.2744],\n","         [-0.3651, -0.1935,  0.4495,  ...,  0.3014,  0.0890,  0.2237]]],\n","       device='cuda:0', grad_fn=<AddBackward0>)"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"TvX_HwjKxCCN","colab_type":"code","outputId":"59ad83b3-249f-4923-f5a8-c6785e372b1a","executionInfo":{"status":"ok","timestamp":1583888398185,"user_tz":-480,"elapsed":970,"user":{"displayName":"Brian Sum","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOvhOiSz4aqmyleNPLH8Uei1dfjQlbNu7-t47v-w=s64","userId":"09953645826188319016"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["# `encoded_layers` is a Python list.\n","print('     Type of encoded_layers: ', type(all_encoder_layers))\n","\n","# Each layer in the list is a torch tensor.\n","print('Tensor shape for each layer: ', all_encoder_layers[0].size())"],"execution_count":0,"outputs":[{"output_type":"stream","text":["     Type of encoded_layers:  <class 'list'>\n","Tensor shape for each layer:  torch.Size([3, 128, 768])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"StmNW3v0ximh","colab_type":"code","outputId":"bb06bdeb-ba4d-4839-d2ab-ec91022ccafe","executionInfo":{"status":"ok","timestamp":1583888405096,"user_tz":-480,"elapsed":842,"user":{"displayName":"Brian Sum","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOvhOiSz4aqmyleNPLH8Uei1dfjQlbNu7-t47v-w=s64","userId":"09953645826188319016"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Concatenate the tensors for all layers. We use `stack` here to\n","# create a new dimension in the tensor.\n","token_embeddings = torch.stack(all_encoder_layers, dim=0)\n","\n","token_embeddings.size()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([12, 3, 128, 768])"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"P--Y7SN2zCXs","colab_type":"code","outputId":"2c6d5138-959e-49ef-ceb5-bdecac026802","executionInfo":{"status":"ok","timestamp":1583888410552,"user_tz":-480,"elapsed":1013,"user":{"displayName":"Brian Sum","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOvhOiSz4aqmyleNPLH8Uei1dfjQlbNu7-t47v-w=s64","userId":"09953645826188319016"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Sum the vectors from the last four layers.\n","sum_vec = torch.sum(token_embeddings[-4:], dim=0)\n","\n","sum_vec.size()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([3, 128, 768])"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"r-jiNRDBKHPE","colab_type":"code","outputId":"23c8b914-7811-4dfd-a746-36641bfcf8a6","executionInfo":{"status":"ok","timestamp":1583888416129,"user_tz":-480,"elapsed":798,"user":{"displayName":"Brian Sum","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOvhOiSz4aqmyleNPLH8Uei1dfjQlbNu7-t47v-w=s64","userId":"09953645826188319016"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Detach the token embeddings from Tensor into Numpy Array\n","wordvec = sum_vec.detach().cpu().numpy()\n","\n","wordvec.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(3, 128, 768)"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"LCFnT1L0Z8Po","colab_type":"code","colab":{}},"source":["output = collections.OrderedDict()\n","for (b, example_index) in enumerate(example_indices):\n","  sent = collections.OrderedDict()\n","  tok = collections.OrderedDict()\n","  for (i, token) in enumerate(features[b].tokens):\n","    a = wordvec[b][i]\n","    tok[token] = a.tolist()\n","    sent[b] = tok\n","    #print(sent)\n","    output.update(sent)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"r3M7pRrrPgDC","colab_type":"code","outputId":"4604fb7b-6f6e-43b4-cc13-88ee5707e9cb","executionInfo":{"status":"ok","timestamp":1583897645275,"user_tz":-480,"elapsed":2831,"user":{"displayName":"Brian Sum","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOvhOiSz4aqmyleNPLH8Uei1dfjQlbNu7-t47v-w=s64","userId":"09953645826188319016"}},"colab":{"base_uri":"https://localhost:8080/","height":54,"output_embedded_package_id":"14a6KKivprzMtaRtPTD8_DG-pc3o2PGJR"}},"source":["print(json.dumps(output))"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"5ktu-p9APMtx","colab_type":"code","colab":{}},"source":["with open(\"bertWordVectors.json\", \"w\", encoding='utf-8') as writer:\n","  writer.write(json.dumps(output) + \"\\n\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"O_1ENwBiMSfH","colab_type":"code","outputId":"cd11ad3b-0b60-4129-9f42-aed10608272b","executionInfo":{"status":"ok","timestamp":1583897701366,"user_tz":-480,"elapsed":5844,"user":{"displayName":"Brian Sum","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOvhOiSz4aqmyleNPLH8Uei1dfjQlbNu7-t47v-w=s64","userId":"09953645826188319016"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Zip up the folder and copy zip file to Google Drive\n","!zip -r /content/bertwordvector.zip /content/bertWordVectors.json\n","!cp -r /content/bertwordvector.zip \"./drive/My Drive/Downloads\""],"execution_count":0,"outputs":[{"output_type":"stream","text":["  adding: content/bertWordVectors.json (deflated 56%)\n"],"name":"stdout"}]}]}